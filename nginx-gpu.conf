user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    keepalive_timeout 65;

    # Upstream for each model
    upstream tinyllama {
        server tinyllama:8000;
    }

    upstream qwen {
        server qwen:8000;
    }

    upstream yi {
        server yi:8000;
    }

    server {
        listen 80;
        server_name _;

        client_max_body_size 10M;
        client_body_buffer_size 1M;

        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # Health check
        location /health {
            return 200 "OK\n";
            add_header Content-Type text/plain;
        }

        # Model list
        location /v1/models {
            default_type application/json;
            return 200 '{
                "object": "list",
                "data": [
                    {"id": "tinyllama", "object": "model"},
                    {"id": "qwen", "object": "model"},
                    {"id": "yi", "object": "model"}
                ]
            }';
        }

        # Route to TinyLlama
        location ~ ^/v1/tinyllama/ {
            rewrite ^/v1/tinyllama/(.*) /v1/$1 break;
            proxy_pass http://tinyllama;
            proxy_set_header Host $host;
            proxy_buffering off;
        }

        # Route to Qwen
        location ~ ^/v1/qwen/ {
            rewrite ^/v1/qwen/(.*) /v1/$1 break;
            proxy_pass http://qwen;
            proxy_set_header Host $host;
            proxy_buffering off;
        }

        # Route to Yi
        location ~ ^/v1/yi/ {
            rewrite ^/v1/yi/(.*) /v1/$1 break;
            proxy_pass http://yi;
            proxy_set_header Host $host;
            proxy_buffering off;
        }

        # Default route
        location / {
            return 200 'Multi-model vLLM server running\n';
            add_header Content-Type text/plain;
        }
    }
}