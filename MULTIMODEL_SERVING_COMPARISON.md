# π”¬ λ©€ν‹°λ¨λΈ μ„λΉ™ μ†”λ£¨μ… λΉ„κµ (RTX 5090)

**ν…μ¤νΈ λ‚ μ§**: 2025-09-18
**ν•λ“μ›¨μ–΄**: NVIDIA RTX 5090 (32GB)
**ν…μ¤νΈ λ¨λΈ**: TinyLlama 1.1B, Qwen 2.5-3B, Yi-6B

## π“ λ©€ν‹°λ¨λΈ μ„λΉ™ λ¥λ ¥ λΉ„κµ

| μ†”λ£¨μ… | λ©€ν‹°λ¨λΈ λ™μ‹ μ‹¤ν–‰ | μ‹¤μ  ν…μ¤νΈ κ²°κ³Ό | λΉ„κ³  |
|--------|-------------------|-----------------|------|
| **vLLM** | β… μ§€μ› | β… 3κ° λ¨λΈ μ„±κ³µ | κ°€μ¥ μ•μ •μ  |
| **SGLang** | β λ¶κ°€λ¥ | β 1κ°λ§ κ°€λ¥ | λ©”λ¨λ¦¬ κ΄€λ¦¬ ν•κ³„ |
| **Ollama** | β… μ§€μ› (λ™μ ) | β… 3κ° λ¨λΈ μ„±κ³µ | GGUF ν¬λ§·, μλ™ μ¤μ™‘ |

## π€ μ„±λ¥ λΉ„κµ (TinyLlama 1.1B κΈ°μ¤€)

| λ©”νΈλ¦­ | vLLM | SGLang | Ollama |
|--------|------|--------|--------|
| **μ²λ¦¬λ‰** | 332.03 tok/s | 69.38 tok/s | ~120 tok/s (μ¶”μ •) |
| **ν‰κ·  μ§€μ—°μ‹κ°„** | 261.73ms | 393.94ms | 824ms (μ²« νΈμ¶) / 44ms (μΊμ‹) |
| **P95 μ§€μ—°μ‹κ°„** | 265.33ms | 538.42ms | N/A |
| **μ„±κ³µλ¥ ** | 99.7% | 100% | 100% |
| **λ©€ν‹°λ¨λΈ** | β… | β | β… |
| **λ©”λ¨λ¦¬ μ‚¬μ©** | ~5GB/λ¨λΈ | ~5GB | 1.3GB (GGUF) |

## π― κ° μ†”λ£¨μ…μ νΉμ§•

### vLLM
**μ¥μ :**
- β… λ©€ν‹°λ¨λΈ λ™μ‹ μ‹¤ν–‰ μ™„λ²½ μ§€μ›
- β… κ°€μ¥ λ†’μ€ μ²λ¦¬λ‰ (332 tok/s)
- β… κ°€μ¥ λ‚®μ€ μ§€μ—°μ‹κ°„ (262ms)
- β… RTX 5090μ—μ„ μ•μ •μ  μ‘λ™
- β… ν‘μ¤€ Docker μ΄λ―Έμ§€ μ‚¬μ©

**λ‹¨μ :**
- κ° λ¨λΈλ§λ‹¤ λ³„λ„ μ»¨ν…μ΄λ„ ν•„μ”
- ν¬νΈ κ΄€λ¦¬ ν•„μ” (λ¨λΈλ³„ λ‹¤λ¥Έ ν¬νΈ)

**κ¶μ¥ μ„¤μ •:**
```bash
docker run -d \
  --runtime nvidia \
  --gpus all \
  -p 8000:8000 \
  vllm/vllm-openai:latest \
  --model MODEL_NAME \
  --gpu-memory-utilization 0.15-0.45 \
  --max-model-len 2048 \
  --enforce-eager
```

### SGLang
**μ¥μ :**
- β… λ‹¨μΌ λ¨λΈ μ„±λ¥ μ•μ •μ 
- β… 100% μ„±κ³µλ¥ 
- β… RadixAttention (RTX 4090 μ΄ν•)

**λ‹¨μ :**
- β RTX 5090μ—μ„ λ©€ν‹°λ¨λΈ λ¶κ°€λ¥
- β μ»¤μ¤ν…€ λΉλ“ ν•„μ”
- β λ§μ€ μµμ ν™” κΈ°λ¥ λΉ„ν™μ„±ν™”
- β λ‚®μ€ μ²λ¦¬λ‰ (69 tok/s)

**μ ν•μ‚¬ν•­:**
- mem-fraction-staticμ΄ μ „μ²΄ GPU κΈ°μ¤€
- μ»¨ν…μ΄λ„ κ°„ λ©”λ¨λ¦¬ κ³µμ  λ¶κ°€
- λ‘ λ²μ§Έ λ¨λΈ μ‹μ‘ μ‹ λ©”λ¨λ¦¬ λ¶€μ΅±

### Ollama
**μ¥μ :**
- β… λ™μ  λ¨λΈ λ΅λ”©/μ–Έλ΅λ”©
- β… μλ™ λ©”λ¨λ¦¬ κ΄€λ¦¬
- β… λ‹¨μΌ API μ—”λ“ν¬μΈνΈ
- β… CPU/GPU νΌν•© μ‹¤ν–‰ κ°€λ¥
- β… RTX 5090μ—μ„ μ •μƒ μ‘λ™ ν™•μΈ
- β… λ§¤μ° ν¨μ¨μ μΈ λ©”λ¨λ¦¬ μ‚¬μ© (GGUF)
- β… λ¨λΈ μΊμ‹±μΌλ΅ λΉ λ¥Έ μ¬νΈμ¶ (44ms)

**λ‹¨μ :**
- GGUF ν¬λ§· λ³€ν™ ν•„μ”
- μ–‘μν™”λ΅ μΈν• ν’μ§ μ†μ‹¤ κ°€λ¥
- μ²« νΈμ¶ μ‹ μ§€μ—°μ‹κ°„μ΄ κΉ€ (824ms)
- λ™μ‹ μ”μ²­ μ²λ¦¬μ— ν•κ³„

**νΉμ§•:**
- μ‚¬μ©ν•μ§€ μ•λ” λ¨λΈ μλ™ μ–Έλ΅λ“ (5λ¶„ ν›„)
- λ©”λ¨λ¦¬ λ¶€μ΅± μ‹ μλ™ μ¤μ™‘
- λ‹¨μΌ ν¬νΈ (11434)λ΅ λ¨λ“  λ¨λΈ μ ‘κ·Ό
- Docker μ»¨ν…μ΄λ„λ΅ κ°„νΈν• λ°°ν¬

## π’΅ κ¶μ¥μ‚¬ν•­

### RTX 5090μ—μ„ λ©€ν‹°λ¨λΈ μ„λΉ™μ΄ ν•„μ”ν• κ²½μ°

**1μμ„: vLLM** β­β­β­β­β­
```yaml
μ΄μ :
- κ²€μ¦λ λ©€ν‹°λ¨λΈ μ§€μ›
- μµκ³  μ„±λ¥ (4.8x faster than SGLang)
- μ•μ •μ  μ΄μ
- ν”„λ΅λ•μ… μ¤€λΉ„ μ™„λ£
```

**2μμ„: Ollama** β­β­β­β­
```yaml
μ΄μ :
- λ™μ  λ¨λΈ κ΄€λ¦¬
- λ©”λ¨λ¦¬ λ§¤μ° ν¨μ¨μ  (GGUF)
- κ°„νΈν• μ„¤μ •
- RTX 5090 μ™„λ²½ μ§€μ›
- λ¨λΈ μΊμ‹±μΌλ΅ λΉ λ¥Έ μ‘λ‹µ
μ¥μ :
- 3κ° λ¨λΈ 8.5GBλ§ μ‚¬μ©
- μλ™ λ©”λ¨λ¦¬ κ΄€λ¦¬
λ‹¨μ :
- GGUF λ³€ν™ ν•„μ”
- μ–‘μν™” ν’μ§ μ†μ‹¤
```

**3μμ„: SGLang** β­β­
```yaml
μ΄μ :
- λ‹¨μΌ λ¨λΈλ§ κ°€λ¥
- λ‚®μ€ μ„±λ¥
- λ³µμ΅ν• μ„¤μ •
μ‚¬μ© μ‹λ‚λ¦¬μ¤:
- λ‹¨μΌ λ¨λΈλ§ ν•„μ”ν• κ²½μ°
- RTX 4090 μ΄ν• GPU
```

## π“ λ©”λ¨λ¦¬ μ‚¬μ© μ „λµ

### vLLM λ©€ν‹°λ¨λΈ λ©”λ¨λ¦¬ ν• λ‹Ή
```
TinyLlama (1.1B): gpu-memory-utilization=0.15 (~5GB)
Qwen (2.5-3B): gpu-memory-utilization=0.25 (~8GB)
Yi (6B): gpu-memory-utilization=0.45 (~14GB)
μ΄ μ‚¬μ©: ~27GB / 32GB (μ—¬μ  5GB)
```

### μ‹¤μ  λ°°ν¬ μμ‹
```bash
# vLLM 3κ° λ¨λΈ λ™μ‹ μ‹¤ν–‰
docker-compose up -d  # docker-compose-vllm-3models.yml μ‚¬μ©

# κ° λ¨λΈ μ ‘κ·Ό
curl http://localhost:40001/v1/completions  # TinyLlama
curl http://localhost:40002/v1/completions  # Qwen
curl http://localhost:40003/v1/completions  # Yi
```

## π§ Ollama μ‹¤μ  ν…μ¤νΈ κ²°κ³Ό

### λ©€ν‹°λ¨λΈ λ™μ  μ „ν™ ν…μ¤νΈ
```bash
TinyLlama (1.1B): 824ms μ‘λ‹µ β†’ 1.3GB GPU μ‚¬μ©
Qwen (2.5-3B): 1437ms μ‘λ‹µ β†’ 4.2GB GPU μ‚¬μ© (λ„μ )
Yi (6B): 1309ms μ‘λ‹µ β†’ 8.5GB GPU μ‚¬μ© (λ„μ )
TinyLlama μ¬νΈμ¶: 44ms (μΊμ‹λ λ¨λΈ)
```

### Ollama λ©”λ¨λ¦¬ ν¨μ¨μ„±
- **TinyLlama**: 1.3GB (vLLM: 5GB)
- **Qwen 2.5-3B**: 2.9GB μ¶”κ°€ (vLLM: 8GB)
- **Yi-6B**: 4.3GB μ¶”κ°€ (vLLM: 14GB)
- **μ΄ μ‚¬μ©**: 8.5GB vs vLLM 27GB (3.2λ°° ν¨μ¨μ )

## π† μµμΆ… κ²°λ΅ 

### μ‚¬μ© μ‚¬λ΅€λ³„ μµμ  μ„ νƒ

**1. κ³ μ„±λ¥ ν”„λ΅λ•μ… μ„λΉ„μ¤: vLLM** β­β­β­β­β­
- μµκ³ μ μ²λ¦¬λ‰κ³Ό μΌκ΄€λ μ§€μ—°μ‹κ°„
- λ™μ‹ μ”μ²­ μ²λ¦¬ λ¥λ ¥ μ°μ
- ν‘μ¤€ λ¨λΈ ν¬λ§· μ‚¬μ©

**2. λ©”λ¨λ¦¬ μ μ•½ ν™κ²½: Ollama** β­β­β­β­
- 3.2λ°° λ©”λ¨λ¦¬ ν¨μ¨
- μλ™ λ©”λ¨λ¦¬ κ΄€λ¦¬
- κ°λ°/ν…μ¤νΈ ν™κ²½ μµμ 

**3. λ‹¨μΌ λ¨λΈ μ„λΉ„μ¤: vLLM λλ” SGLang**
- vLLM: RTX 5090μ—μ„ μµκ³  μ„±λ¥
- SGLang: RTX 4090 μ΄ν•μ—μ„ κ³ λ ¤

---

*ν…μ¤νΈ μ™„λ£: 2025-09-18 17:59*
*κ²€μ¦λ ν…μ¤νΈ: vLLM/SGLang 600+ λ²¤μΉλ§ν¬, Ollama λ©€ν‹°λ¨λΈ ν…μ¤νΈ*
*λ°μ΄ν„° κΈ°λ° κ¶μ¥μ‚¬ν•­*